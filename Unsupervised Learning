"""
Created on Thu Mar 28 17:39:26 2019

@author: lauraschweigert

Working Directory:
    /Users/lauraschweigert/Dropbox/Hult/Module B/Machine Learning/PyMLCourse

Machine Learning Final Exam
    Mobile App Research Survey

"""

# Importing libraries
from sklearn.preprocessing import StandardScaler # standard scaler
from sklearn.decomposition import PCA # principal component analysis
from scipy.cluster.hierarchy import dendrogram, linkage # dendrograms
from sklearn.cluster import KMeans # k-means clustering
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


# Setting pandas print options
pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)


# Importing dataset
survey_df = pd.read_excel('finalExam_Mobile_App_Survey_Data_final_exam-2.xlsx')


########################
# EDA
########################

survey_df.info()

""" 
Looking at this and the data dictionary we can see that there are three types
of variables: demographic, behavioral and psychometric.
"""

survey_df.describe()

########################
# Step 1: Remove demographic information
########################

"""
Demographic Information
q1 Age
q48 Education
q49 Maritial Status
q50 Age group of children (r1: no children, r5: children 18 or older)
q54 race
q55 hispanic or latino
q56 household income
q57 gender

We want build clusters based on only the behavioral and psychometric variables."
"""

survey_features_reduced = survey_df.iloc[ : , 2:-11]



########################
# Renaming columns and reversing questions
########################

""" 
Targeting specific questions that are asked reversely (survey technique) and
reverse the answer, so that positive feelings (agree) towards apps/tech/etc.
are expressed with lower values and negative feelings (disagree) with higher values.
We want to be able to interpret them in the same way.
"""

### Question 12

# create a new column
survey_features_reduced['rev_q12'] = -100 

# reverse original column
survey_features_reduced['rev_q12'][survey_features_reduced['q12']==1] = 6
survey_features_reduced['rev_q12'][survey_features_reduced['q12']==2] = 5
survey_features_reduced['rev_q12'][survey_features_reduced['q12']==3] = 4
survey_features_reduced['rev_q12'][survey_features_reduced['q12']==4] = 3
survey_features_reduced['rev_q12'][survey_features_reduced['q12']==5] = 2
survey_features_reduced['rev_q12'][survey_features_reduced['q12']==6] = 1

survey_features_reduced['q12'].value_counts()
survey_features_reduced['rev_q12'].value_counts()

# drop the old column
survey_features_reduced = survey_features_reduced.drop(columns=['q12'], axis = 1)


### Question 24 r4

# create a new column
survey_features_reduced['rev_q24r4'] = -100 

# reverse original column
survey_features_reduced['rev_q24r4'][survey_features_reduced['q24r4']==1] = 6
survey_features_reduced['rev_q24r4'][survey_features_reduced['q24r4']==2] = 5
survey_features_reduced['rev_q24r4'][survey_features_reduced['q24r4']==3] = 4
survey_features_reduced['rev_q24r4'][survey_features_reduced['q24r4']==4] = 3
survey_features_reduced['rev_q24r4'][survey_features_reduced['q24r4']==5] = 2
survey_features_reduced['rev_q24r4'][survey_features_reduced['q24r4']==6] = 1

survey_features_reduced['rev_q24r4'].value_counts() # did it work?

# drop the old column
survey_features_reduced = survey_features_reduced.drop(columns=['q24r4'], axis = 1)


### Question 24 r9

# create a new column
survey_features_reduced['rev_q24r9'] = -100 

# reverse original column
survey_features_reduced['rev_q24r9'][survey_features_reduced['q24r9']==1] = 6
survey_features_reduced['rev_q24r9'][survey_features_reduced['q24r9']==2] = 5
survey_features_reduced['rev_q24r9'][survey_features_reduced['q24r9']==3] = 4
survey_features_reduced['rev_q24r9'][survey_features_reduced['q24r9']==4] = 3
survey_features_reduced['rev_q24r9'][survey_features_reduced['q24r9']==5] = 2
survey_features_reduced['rev_q24r9'][survey_features_reduced['q24r9']==6] = 1

survey_features_reduced['rev_q24r9'].value_counts() # did it work?

# drop the old column
survey_features_reduced = survey_features_reduced.drop(columns=['q24r9'], axis = 1)


### Question 24 r12

# create a new column
survey_features_reduced['rev_q24r12'] = -100 

# reverse original column
survey_features_reduced['rev_q24r12'][survey_features_reduced['q24r12']==1] = 6
survey_features_reduced['rev_q24r12'][survey_features_reduced['q24r12']==2] = 5
survey_features_reduced['rev_q24r12'][survey_features_reduced['q24r12']==3] = 4
survey_features_reduced['rev_q24r12'][survey_features_reduced['q24r12']==4] = 3
survey_features_reduced['rev_q24r12'][survey_features_reduced['q24r12']==5] = 2
survey_features_reduced['rev_q24r12'][survey_features_reduced['q24r12']==6] = 1

survey_features_reduced['rev_q24r12'].value_counts() # did it work?

# drop the old column
survey_features_reduced = survey_features_reduced.drop(columns=['q24r12'], axis = 1)


### Question 25 r6

# create a new column
survey_features_reduced['rev_q25r6'] = -100 

# reverse original column
survey_features_reduced['rev_q25r6'][survey_features_reduced['q25r6']==1] = 6
survey_features_reduced['rev_q25r6'][survey_features_reduced['q25r6']==2] = 5
survey_features_reduced['rev_q25r6'][survey_features_reduced['q25r6']==3] = 4
survey_features_reduced['rev_q25r6'][survey_features_reduced['q25r6']==4] = 3
survey_features_reduced['rev_q25r6'][survey_features_reduced['q25r6']==5] = 2
survey_features_reduced['rev_q25r6'][survey_features_reduced['q25r6']==6] = 1

survey_features_reduced['rev_q25r6'].value_counts() # did it work?

# drop the old column
survey_features_reduced = survey_features_reduced.drop(columns=['q25r6'], axis = 1)



### Question 25 r12

# create a new column
survey_features_reduced['rev_q25r12'] = -100 

# reverse original column
survey_features_reduced['rev_q25r12'][survey_features_reduced['q25r12']==1] = 6
survey_features_reduced['rev_q25r12'][survey_features_reduced['q25r12']==2] = 5
survey_features_reduced['rev_q25r12'][survey_features_reduced['q25r12']==3] = 4
survey_features_reduced['rev_q25r12'][survey_features_reduced['q25r12']==4] = 3
survey_features_reduced['rev_q25r12'][survey_features_reduced['q25r12']==5] = 2
survey_features_reduced['rev_q25r12'][survey_features_reduced['q25r12']==6] = 1

survey_features_reduced['rev_q25r12'].value_counts() # did it work?

# drop the old column
survey_features_reduced = survey_features_reduced.drop(columns=['q25r12'], axis = 1)


########################
# Step 2: Scale to get equal variance
########################

"Scaling variance in order to accurately being able to measure the distance."

# instanciate scaling object
scaler = StandardScaler()

# fitting
scaler.fit(survey_features_reduced)

# transforming
X_scaled_reduced = scaler.transform(survey_features_reduced)


########################
# Step 3: Run PCA without limiting the number of components
########################

"Principal Component Analysis to find clusters of observations."

# instanciate the PCA
survey_pca_reduced = PCA(n_components = None,
                           random_state = 508)


# fitting
survey_pca_reduced.fit(X_scaled_reduced)

# transforming
X_pca_reduced = survey_pca_reduced.transform(X_scaled_reduced)


########################
# Step 4: Analyze the scree plot to determine how many components to retain
########################


fig, ax = plt.subplots(figsize=(10, 8))

features = range(survey_pca_reduced.n_components_)


plt.plot(features,
         survey_pca_reduced.explained_variance_ratio_, 
         linewidth = 2,
         marker = 'o',
         markersize = 10,
         markeredgecolor = 'black',
         markerfacecolor = 'grey')


plt.title('Marketing App Survey Scree Plot')
plt.xlabel('PCA feature')
plt.ylabel('Explained Variance')
plt.xticks(features)
plt.show()

########################
# Step 5: Run PCA again based on the desired number of components
########################

"Clustering the observations into 4 components."

# rebuild PCA based on blueprint
survey_pca_reduced = PCA(n_components = 4, 
                           random_state = 508)

# fitting
survey_pca_reduced.fit(X_scaled_reduced)


########################
# Step 6: Analyze factor loadings to understand principal components
########################

factor_loadings_df = pd.DataFrame(pd.np.transpose(survey_pca_reduced.components_))


factor_loadings_df = factor_loadings_df.set_index(survey_df.columns[2:-11])


print(factor_loadings_df)


factor_loadings_df.to_excel('FinalExam_survey_factor_loadings.xlsx')
# identify needs in excel
# agree - disagree


########################
# Step 7: Analyze factor strengths per customer
########################

# Transform 
X_pca_reduced = survey_pca_reduced.transform(X_scaled_reduced)
" Who felt strongly about what need"

X_pca_df = pd.DataFrame(X_pca_reduced)
# new dataset to put into clustering


########################
# Step 8: Rename your principal components and reattach demographic information
########################

X_pca_df.columns = ['time_management', 'tech_averse', 'music','paying_introverted']


###############################################################################
# Combining PCA and Clustering
###############################################################################

########################
# Step 1: Take your transformed dataframe
########################

print(X_pca_df.head(n = 5))

print(pd.np.var(X_pca_df)) # high variance


########################
# Step 2: Scale to get equal variance
########################

scaler = StandardScaler()


scaler.fit(X_pca_df)


X_pca_clust = scaler.transform(X_pca_df)


X_pca_clust_df = pd.DataFrame(X_pca_clust)


print(pd.np.var(X_pca_clust_df)) # standardized


X_pca_clust_df.columns = X_pca_df.columns


########################
# Before step 3: Dendogram to know number of clusters
########################

standard_mergings_ward = linkage(y = X_pca_clust_df,
                                 method = 'ward')

fig, ax = plt.subplots(figsize=(8, 8))

dendrogram(Z = standard_mergings_ward,
           leaf_rotation = 90,
           leaf_font_size = 6)

plt.savefig('standard_hierarchical_clust_ward.png')
plt.show()

########################
# Step 3: Experiment with different numbers of clusters
########################

survey_k_pca = KMeans(n_clusters = 4,
                         random_state = 508)


survey_k_pca.fit(X_pca_clust_df)


survey_kmeans_pca = pd.DataFrame({'cluster': survey_k_pca.labels_})


print(survey_kmeans_pca.iloc[: , 0].value_counts())


########################
# Step 4: Analyze cluster centers
########################

centroids_pca = survey_k_pca.cluster_centers_


centroids_pca_df = pd.DataFrame(centroids_pca)


# Rename your principal components
centroids_pca_df.columns = ['time_management',
                            'tech_averse',
                            'music',
                            'paying_introverted']


print(centroids_pca_df)


# Sending data to Excel
centroids_pca_df.to_excel('survey_pca_centriods.xlsx')
# submit this excel file


########################
# Step 5: Analyze cluster memberships
########################

clst_pca_df = pd.concat([survey_kmeans_pca,
                         X_pca_clust_df],
                         axis = 1)


print(clst_pca_df)

clst_pca_df['cluster'].value_counts() # looking at the distribution of clusters

########################
# Step 6: Reattach demographic information
########################

"""
Demographic Information
q1  Age
q48 Education
q49 Maritial Status
q50 Age group of children (r1: no children, r5: children 18 or older)
q54 race
q55 hispanic or latino
q56 household income
q57 gender
"""

# Concatenating the demographic information for race and gender
final_pca_clust_df = pd.concat([survey_df.loc[ : , ['q1', 'q57','q56']],
                                clst_pca_df],
                                axis = 1)

print(final_pca_clust_df.head(n = 5))


# Renaming Age (q1)

age_names = {1 : 'Under_18',
             2 : '18-24',
             3 : '25-29',
             4 : '30-34',
             5 : '35-39',
             6 : '40-44',
             7 : '45-49',
             8 : '50-54',
             9 : '55-59',
             10 : '60-64',
             11 : '65_or_over',
             12 : '65_or_over'}

final_pca_clust_df['q1'].replace(age_names, inplace = True)


# Renaming Household Income (q56)

income_names = {1 : 'under_30k',
                2 : 'under_30k',
                3 : 'under_30k',
                4 : 'under_30k',
                5 : '30k-60k',
                6 : '30k-60k',
                7 : '30k-60k',
                8 : '60k-90k',
                9 : '60k-90k',
                10 : '60k-90k',
                11 : 'above_90k',
                12 : 'above_90k',
                13 : 'above_90k',
                14 : 'above_90k'}

final_pca_clust_df['q56'].replace(income_names, inplace = True)


# Renaming gender (q57)

gender_names = {1 : 'male',
                2 : 'female'}

final_pca_clust_df['q57'].replace(gender_names, inplace = True)


# Adding a productivity step

data_df = final_pca_clust_df


########################
# Step 7: Analyze in more detail 
########################

"I looked at the different need for time management between gender,age and income groups ."

##### Gender (q57) #########

# time_management 
fig, ax = plt.subplots(figsize = (8, 4))
sns.boxplot(x = 'q57',
            y = 'time_management',
            hue = 'cluster',
            data = data_df)

plt.ylim(-2, 4)
plt.tight_layout()
plt.show()

"males in cluster 3 have a slightly higher need (more negative) for time management"


##### Age (q1) #########

# time_management
fig, ax = plt.subplots(figsize = (8, 4))
sns.boxplot(x = 'q1',
            y = 'time_management',
            hue = 'cluster',
            data = data_df)

plt.ylim(-2, 4)
plt.tight_layout()
plt.show()

"50-54 year olds in cluster 3 have a higher need (more negative) for time management"


##### Income (q56) #########

# time_management 
fig, ax = plt.subplots(figsize = (8, 4))
sns.boxplot(x = 'q56',
            y = 'time_management',
            hue = 'cluster',
            data = data_df)

plt.ylim(-2, 4)
plt.tight_layout()
plt.show()

"people with an income above 90k in cluster 3 have a  higher need (more negative) for time management"
